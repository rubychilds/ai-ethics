# **[Fairlearn](https://fairlearn.github.io/)**

**Overall evaluation**

_Technical Implementation_

Useful: 4/5

Comprehensive: 4/5

Technical scalability: 5/5

Easy to customize (data): 5/5

Easy to customize (visualizations / analyses): 5/5

Easy to integrate: 5/5

Robustness: ?/5

_User-friendliness (system usability scale)_

Answer with strongly agree (5), agree (4), neutral (3), disagree (2), strongly disagree (1)

Feel free to add comments and justifications!

I think that I would like to use this system frequently: 5, I feel it has more of what Iâ€™d need and it seems easy to integration

I found the system unnecessarily complex: 1

I thought the system was easy to use: 4 (-1 for missing documentation)

I think that I would need the support of a technical person to be able to use this system: 3

I found the various functions in this system were well integrated: 5, clustered in classes

I thought there was too much inconsistency in this system: 1

I would imagine that most people would learn to use this system very quickly: 3, needs more documentation and case studies

I found the system very cumbersome to use: 1

I felt very confident using the system: 4

I needed to learn a lot of things before I could get going with this system: 1

**Description of the tool**

Assess the fairness of their machine learning models and mitigate unfairness. It can assess existing models and train new models with fairness in mind. Compare models and make trade-offs between fairness and model performance.

**Best for: **

-

Detection bias in binary classification model predictors and applying mitigation techniques
**Pros & cons**

Pros:

-

Easy to install

-

Includes dashboard to guide the user

-

Includes several mitigation techniques

-

It includes equalised odds among other fairness definitions

1.

**Limitations, especially any technical issues**

-

Lack of documentation on mitigation techniques

-

There are examples, but no case studies going more in depth
**Case study demo with screenshots**

Add in screenshots with descriptions on the data set used!

<p id="gdcalert17" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to _media/image17.png). Store image on your image server and adjust path/filename/extension if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert18">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>

![alt_text](_media/image17.png "image_tooltip")

<p id="gdcalert18" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to _media/image18.png). Store image on your image server and adjust path/filename/extension if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert19">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>

![alt_text](_media/image18.png "image_tooltip")
